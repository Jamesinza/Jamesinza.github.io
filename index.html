<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Machine Learning Systems & Experiments</title>
  <meta name="description" content="Experimental machine learning systems focused on adaptive capacity, learning dynamics, and failure modes under real constraints.">
  <link rel="stylesheet" href="style.css">
</head>
<body>

<main>

  <h1>Machine Learning Systems Experiments</h1>

  <p>
    I explore machine learning systems that adapt their structure, learning rules,
    and capacity over time, especially under constrained compute and non-stationary data.
    My work prioritizes understanding <em>how</em> models fail, drift, destabilize, and recover.
  </p>

  <p>
    Rather than optimizing for benchmarks or architectural novelty, these experiments
    probe learning dynamics, resource usage, and emergent behavior in systems that are
    allowed to change themselves.
  </p>

  <hr>

  <h2>Core Themes</h2>
  <ul>
    <li>Adaptive and over-parameterized learning systems</li>
    <li>Self-modifying neural architectures</li>
    <li>Pruning, growth, and learned plasticity</li>
    <li>Failure modes in non-stationary environments</li>
    <li>Training under memory and compute constraints</li>
    <li>Experimental use of TensorFlow / Keras at the system level</li>
  </ul>

  <hr>

  <h2>Selected Experiments</h2>

  <ul>
    <li>
      <strong>Adaptive Over-Parameterization</strong><br>
      Train with excess capacity, then let the data decide what survives.<br>
      <a href="experiments/adaptive-overparameterization.html">Read experiment →</a>
    </li>

    <li>
      <strong>Self-Modifying Neural Systems</strong><br>
      Models that change their own connectivity, plasticity rules, and capacity during training.<br>
      <a href="experiments/self-modifying-systems.html">Read experiment →</a>
    </li>

    <li>
      <strong>Meta Learner Subprocessing</strong><br>
      Training orchestration strategies for resource-constrained environments.<br>
      <a href="experiments/resource-constrained-training.html">Read experiment →</a>
    </li>

    <li>
      <strong>Autonomy & Emergent Failure</strong><br>
      Early exploration of autonomous learning systems and why they destabilize.<br>
      <a href="experiments/autonomy.html">Read experiment →</a>
    </li>
  </ul>

  <hr>

  <h2>Notes & Observations</h2>
  <ul>
    <li><a href="notes/failure-modes.html">Failure modes of adaptive systems</a></li>
    <li><a href="notes/nonstationarity.html">Why static architectures fail under drift</a></li>
    <li><a href="notes/learning-dynamics.html">Learning dynamics over architectural polish</a></li>
  </ul>

  <hr>

  <h2>What I’m Looking For</h2>
  <p>
    I am interested in work that sits between research and engineering:
    building, stress-testing, and evolving learning systems rather than deploying
    fixed models at scale.
  </p>

  <p>
    Ideal environments value experimentation, long-horizon thinking,
    and a willingness to explore instability, failure, and unconventional approaches.
  </p>

  <p>
    Relevant domains include:
  </p>

  <ul>
    <li>Advanced applied machine learning</li>
    <li>Research engineering</li>
    <li>Autonomous or adaptive systems</li>
    <li>Quantitative research</li>
    <li>Resource-constrained or non-funded research environments</li>
  </ul>

  <hr>

  <p>
    Code and experiments are available on
    <a href="https://github.com/your-username">GitHub</a>.
  </p>

</main>

</body>
</html>

